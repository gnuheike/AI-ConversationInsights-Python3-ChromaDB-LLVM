{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Telegram Analyzer Notebook\n",
    "\n",
    "This notebook demonstrates how to use the Telegram Analyzer package to process and analyze Telegram chat messages.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Telegram Analyzer is a tool that allows you to:\n",
    "\n",
    "1. Parse JSON Telegram message exports\n",
    "2. Load messages into ChromaDB for semantic search\n",
    "3. Query the database to ask questions about the message content\n",
    "4. Generate answers using Ollama LLM models\n",
    "\n",
    "This notebook will walk you through each step of the process.\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules from the Telegram Analyzer package.\n"
   ],
   "id": "fbc121e30a2defb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import required modules\n",
    "import os\n",
    "\n",
    "# Import Telegram Analyzer modules\n",
    "from telegram_analyzer import config\n",
    "from telegram_analyzer.data_processing import TelegramDataProcessor\n",
    "from telegram_analyzer.database import ChromaDBManager\n",
    "from telegram_analyzer.logging import setup_logging\n",
    "from telegram_analyzer.query import QueryProcessor, answer_question\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging(log_level=\"INFO\")\n",
    "logger.info(\"Telegram Analyzer notebook initialized\")\n"
   ],
   "id": "5aef4ddc0fbe6521"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Configuration\n",
    "\n",
    "Let's examine the default configuration settings for the Telegram Analyzer.\n"
   ],
   "id": "51ea2a590035e90d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display configuration settings\n",
    "print(f\"ChromaDB Settings:\\n{config.CHROMADB_SETTINGS}\\n\")\n",
    "print(f\"Collection Name: {config.COLLECTION_NAME}\\n\")\n",
    "print(f\"Sentence Model:\\n{config.SENTENCE_MODEL}\\n\")\n",
    "print(f\"Query Top K: {config.QUERY_TOP_K}\\n\")\n",
    "print(f\"Ollama Model:\\n{config.OLLAMA_MODEL}\\n\")\n"
   ],
   "id": "1fb323c1e14419e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Loading Telegram Data\n",
    "\n",
    "The first step is to load and process the Telegram chat data from a JSON export file. \n",
    "\n",
    "### How to export Telegram chat data\n",
    "\n",
    "1. Open Telegram Desktop\n",
    "2. Select the chat you want to export\n",
    "3. Click on the three dots in the top-right corner\n",
    "4. Select \"Export chat history\"\n",
    "5. Choose JSON format\n",
    "6. Click \"Export\"\n",
    "\n",
    "Now, let's load the data from the exported JSON file.\n"
   ],
   "id": "da5b8cf9f8ad546"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set the path to your Telegram JSON export file\n",
    "# Replace this with the path to your actual file\n",
    "json_file_path = \"path/to/your/telegram_export.json\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(json_file_path):\n",
    "    print(f\"File not found: {json_file_path}\")\n",
    "    print(\"Please update the path to your Telegram JSON export file.\")\n",
    "else:\n",
    "    # Load messages using the TelegramDataProcessor\n",
    "    processor = TelegramDataProcessor(json_file_path)\n",
    "    messages = processor.load_messages()\n",
    "\n",
    "    print(f\"Loaded {len(messages)} messages from {json_file_path}\")\n",
    "\n",
    "    # Display the first few messages\n",
    "    print(\"\\nSample messages:\")\n",
    "    for i, msg in enumerate(messages[:5]):\n",
    "        print(f\"\\nMessage {i + 1}:\")\n",
    "        print(f\"From: {msg['from']}\")\n",
    "        print(f\"Date: {msg['date']}\")\n",
    "        print(f\"Text: {msg['text'][:100]}...\" if len(msg['text']) > 100 else f\"Text: {msg['text']}\")\n"
   ],
   "id": "ad2cf738810a8c2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Loading Data into ChromaDB\n",
    "\n",
    "Now that we have loaded the messages, let's store them in ChromaDB for semantic search. ChromaDB will generate embeddings for each message, allowing us to find semantically similar messages later.\n"
   ],
   "id": "89da10102c3b848b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the ChromaDB manager\n",
    "db_manager = ChromaDBManager(\n",
    "    collection_name=\"notebook_demo\",  # Use a separate collection for this notebook\n",
    "    model_name=config.SENTENCE_MODEL[\"name\"],\n",
    "    device=config.SENTENCE_MODEL[\"device\"]\n",
    ")\n",
    "\n",
    "# Check if we have messages to load\n",
    "if 'messages' in locals() and messages:\n",
    "    # Load messages into ChromaDB\n",
    "    # Note: This may take some time depending on the number of messages\n",
    "    try:\n",
    "        count = db_manager.load_messages(\n",
    "            messages=messages,\n",
    "            batch_size=1000,  # Smaller batch size for demonstration\n",
    "            reset_collection=True  # Reset the collection before loading\n",
    "        )\n",
    "        print(f\"Successfully loaded {count} messages into ChromaDB collection 'notebook_demo'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading messages into ChromaDB: {e}\")\n",
    "else:\n",
    "    print(\"No messages to load. Please run the previous cell with a valid JSON file path.\")\n"
   ],
   "id": "165901bf77234ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Checking the Database\n",
    "\n",
    "Let's check the status of our ChromaDB collection to ensure the data was loaded correctly.\n"
   ],
   "id": "9f900d5f694c48c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get information about the collection\n",
    "try:\n",
    "    info = db_manager.get_collection_info()\n",
    "\n",
    "    print(f\"Collection: {info['collection_name']}\")\n",
    "    print(f\"Document count: {info['document_count']}\")\n",
    "    print(f\"Persist directory: {info['persist_directory']}\")\n",
    "    print(f\"Directory size: {info['directory_size_gb']:.2f} GB\")\n",
    "    print(f\"Model: {info['model_name']}\")\n",
    "    print(f\"Device: {info['device']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting collection info: {e}\")\n"
   ],
   "id": "5153895be0e2f36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Querying the Database\n",
    "\n",
    "Now that we have loaded the data into ChromaDB, we can query it to find relevant messages based on semantic similarity.\n"
   ],
   "id": "e1b86c746a5b7118"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define a query\n",
    "query_text = \"What are the main topics discussed in this chat?\"\n",
    "\n",
    "# Query the database\n",
    "try:\n",
    "    relevant_messages = db_manager.query(\n",
    "        query_text=query_text,\n",
    "        top_k=10  # Get the top 10 most relevant messages\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(relevant_messages)} relevant messages for query: '{query_text}'\\n\")\n",
    "\n",
    "    # Display the relevant messages\n",
    "    for i, msg in enumerate(relevant_messages):\n",
    "        print(f\"\\nRelevant Message {i + 1}:\")\n",
    "        print(f\"From: {msg['metadata']['from']}\")\n",
    "        print(f\"Date: {msg['metadata']['date']}\")\n",
    "        print(f\"Text: {msg['text'][:150]}...\" if len(msg['text']) > 150 else f\"Text: {msg['text']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error querying the database: {e}\")\n"
   ],
   "id": "e272ded0448438c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Generating Answers with LLM\n",
    "\n",
    "Finally, let's use the QueryProcessor to generate answers to questions about the chat using an LLM (via Ollama).\n",
    "\n",
    "**Note**: This requires Ollama to be installed and running locally with the specified model pulled.\n"
   ],
   "id": "81567221aa4e9aca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the QueryProcessor\n",
    "query_processor = QueryProcessor(\n",
    "    collection_name=\"notebook_demo\",  # Use the same collection we created earlier\n",
    "    model_name=config.OLLAMA_MODEL[\"name\"],\n",
    "    model_options=config.OLLAMA_MODEL[\"options\"]\n",
    ")\n",
    "\n",
    "# Define a question\n",
    "question = \"What are the main topics discussed in this chat?\"\n",
    "\n",
    "# Generate an answer\n",
    "try:\n",
    "    result = query_processor.answer_question(\n",
    "        question=question,\n",
    "        top_k=1000  # Use more context for better answers\n",
    "    )\n",
    "\n",
    "    print(f\"Question: {result['question']}\\n\")\n",
    "    print(f\"Answer: {result['answer']}\\n\")\n",
    "    print(f\"Processing time: {result['metadata']['processing_time']:.2f} seconds\")\n",
    "    print(f\"Relevant messages used: {result['metadata']['relevant_messages_count']}\")\n",
    "    print(f\"Model used: {result['metadata']['model']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating answer: {e}\")\n"
   ],
   "id": "7c7ab7ae09945c05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Ask Multiple Questions\n",
    "\n",
    "Let's ask a few more questions to demonstrate the system's capabilities.\n"
   ],
   "id": "c1156e83acb3c6ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define a list of questions\n",
    "questions = [\n",
    "    \"Who are the most active participants in this chat?\",\n",
    "    \"What was discussed about machine learning?\",\n",
    "    \"Are there any important dates or events mentioned?\",\n",
    "    \"What are the sentiments expressed in this conversation?\"\n",
    "]\n",
    "\n",
    "# Process each question\n",
    "for question in questions:\n",
    "    try:\n",
    "        print(f\"\\n{'=' * 80}\\n\")\n",
    "        print(f\"Question: {question}\\n\")\n",
    "\n",
    "        # Generate answer\n",
    "        answer = answer_question(\n",
    "            question=question,\n",
    "            collection_name=\"notebook_demo\",\n",
    "            model_name=config.OLLAMA_MODEL[\"name\"],\n",
    "            top_k=1000\n",
    "        )\n",
    "\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question '{question}': {e}\")\n"
   ],
   "id": "a1ea8fca68060d44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Visualizing Message Activity\n",
    "\n",
    "Let's create a simple visualization of message activity over time.\n"
   ],
   "id": "6189d035d0edd33d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T20:47:04.539903Z",
     "start_time": "2025-06-22T20:46:53.371381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import visualization libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "\n",
    "    # Check if we have messages\n",
    "    if 'messages' in locals() and messages:\n",
    "        # Extract dates from messages\n",
    "        dates = []\n",
    "        senders = []\n",
    "\n",
    "        for msg in messages:\n",
    "            # Extract date - assuming format like \"2023-01-01T12:34:56\"\n",
    "            date_str = msg['date']\n",
    "            if date_str and re.match(r'\\d{4}-\\d{2}-\\d{2}', date_str):\n",
    "                try:\n",
    "                    # Extract just the date part\n",
    "                    date = datetime.fromisoformat(date_str.split('T')[0])\n",
    "                    dates.append(date)\n",
    "                    senders.append(msg['from'])\n",
    "                except (ValueError, IndexError):\n",
    "                    pass\n",
    "\n",
    "        if dates:\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame({'date': dates, 'sender': senders})\n",
    "\n",
    "            # Group by date and count messages\n",
    "            daily_counts = df.groupby(df['date'].dt.date).size()\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            daily_counts.plot(kind='bar')\n",
    "            plt.title('Message Activity by Date')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Number of Messages')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot message count by sender\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sender_counts = df['sender'].value_counts().head(10)  # Top 10 senders\n",
    "            sender_counts.plot(kind='bar')\n",
    "            plt.title('Top 10 Most Active Participants')\n",
    "            plt.xlabel('Sender')\n",
    "            plt.ylabel('Number of Messages')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No valid dates found in the messages.\")\n",
    "    else:\n",
    "        print(\"No messages available for visualization. Please run the data loading cell first.\")\n",
    "except ImportError:\n",
    "    print(\"Visualization requires pandas and matplotlib. Install them with: pip install pandas matplotlib\")\n"
   ],
   "id": "f8d1cd975a69581e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No messages available for visualization. Please run the data loading cell first.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Telegram Analyzer package to:\n",
    "\n",
    "1. Load and process Telegram chat data from a JSON export\n",
    "2. Store the messages in ChromaDB for semantic search\n",
    "3. Query the database to find relevant messages\n",
    "4. Generate answers to questions about the chat using an LLM\n",
    "5. Visualize message activity\n",
    "\n",
    "This approach allows for powerful analysis of Telegram conversations, enabling you to extract insights and answer questions about the content of your chats.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try with your own Telegram chat exports\n",
    "- Experiment with different LLM models in Ollama\n",
    "- Develop more advanced visualizations and analyses\n",
    "- Integrate with other NLP tools for sentiment analysis, topic modeling, etc."
   ],
   "id": "6eb9f99757c34571"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
